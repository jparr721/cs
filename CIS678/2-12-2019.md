# Feb 12, 2019

## Accuracy

**Precision v. Recall**

- Precision: Measures the success rate of a classifier
  - Precision = true positive / true positive + false positive
  - Determines how confident that a positive prediction <u>is</u> positive.
- Recall: Measures overall success rate in classifying
  - Recall = true positive / true positive + false negative
  - How confident that all positives have been found

## Association Rules

**"Basket" Analysis**

- rule:
  - x -> y: x implies y
    - x -> antecedent
    - y -> consequent
- Confidence:
  - Conditional probability p(y | x)
  - Measures "strength" of rule
  - Range: close to 1.0 >> p(y)
  - confident(x -> y) = p(y | x) = p(x n y) / p(x) = #who got x and y / #who got just x
- Support:
  - Based on sample size
  - Measures the statistical significance of a rule
  - support(X, y) = p(x n y) = # who got x and y / #people total

## Recommender System

Operates off of no customer feedback usually

"A priori" algorithm takes collection of sets and returns frequent subsets

**Steps**

1. Find frequent item sets(Establish support)
   1. Find frequent k-item sets
   2. Generate k + 1 item sets w/ strong support
2. Generate Association Rules
   1. Rules: Split item sets into k - 1 antecedents + 1 consequent
   2. Keep Rules w/ strong confidence
   3. Combine to find 2-consequent rules